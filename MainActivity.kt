package com.example.fogsonarimport android.Manifestimport android.content.pm.PackageManagerimport android.media.AudioFormatimport android.media.AudioRecordimport android.media.MediaRecorderimport android.os.Bundleimport android.util.Logimport android.widget.Buttonimport android.widget.TextViewimport androidx.appcompat.app.AppCompatActivityimport androidx.core.app.ActivityCompatimport androidx.core.content.ContextCompatimport kotlinx.coroutines.*import kotlin.math.cosimport kotlin.math.sinimport kotlin.math.sqrtimport kotlin.math.PIclass MainActivity : AppCompatActivity() {    private val RECORD_AUDIO_PERMISSION_REQUEST_CODE = 101    private var audioRecord: AudioRecord? = null    private var isRecording = false    private val scope = CoroutineScope(Dispatchers.Default)    private var audioJob: Job? = null    private lateinit var statusTextView: TextView    private lateinit var startStopButton: Button    private lateinit var detectedFrequencyTextView: TextView    private lateinit var logTextView: TextView // For logging events    // Audio configuration    private val SAMPLE_RATE = 44100 // Hz    private val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO    private val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT    // FFT_SIZE should be a power of 2 for efficiency    private val FFT_SIZE = 1024    // Buffer size should be at least FFT_SIZE * 2 (for real and imag, or just to hold more data)    private val BUFFER_SIZE = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT) * 2    // Target frequencies for triggering    private val TARGET_FREQUENCIES = setOf(440.0, 528.0) // Hz    private val FREQUENCY_TOLERANCE = 5.0 // +/- Hz for detection    override fun onCreate(savedInstanceState: Bundle?) {        super.onCreate(savedInstanceState)        setContentView(R.layout.activity_main)        statusTextView = findViewById(R.id.statusTextView)        startStopButton = findViewById(R.id.startStopButton)        detectedFrequencyTextView = findViewById(R.id.detectedFrequencyTextView)        logTextView = findViewById(R.id.logTextView)        startStopButton.setOnClickListener {            if (isRecording) {                stopRecording()            } else {                checkAndStartRecording()            }        }    }    private fun checkAndStartRecording() {        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), RECORD_AUDIO_PERMISSION_REQUEST_CODE)        } else {            startRecording()        }    }    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) {        super.onRequestPermissionsResult(requestCode, permissions, grantResults)        if (requestCode == RECORD_AUDIO_PERMISSION_REQUEST_CODE) {            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {                startRecording()            } else {                statusTextView.text = "Microphone permission denied."            }        }    }    private fun startRecording() {        if (audioRecord == null) {            audioRecord = AudioRecord(                MediaRecorder.AudioSource.MIC,                SAMPLE_RATE,                CHANNEL_CONFIG,                AUDIO_FORMAT,                BUFFER_SIZE            )        }        if (audioRecord?.state == AudioRecord.STATE_INITIALIZED) {            audioRecord?.startRecording()            isRecording = true            statusTextView.text = "Recording audio..."            startStopButton.text = "Stop Sonar"            appendLog("Sonar started.")            audioJob = scope.launch {                val audioBuffer = ShortArray(FFT_SIZE) // Use FFT_SIZE for the buffer to process in chunks                while (isRecording) {                    val read = audioRecord?.read(audioBuffer, 0, audioBuffer.size) ?: 0                    if (read == FFT_SIZE) { // Ensure we have enough samples for FFT                        val (detectedFreq, triggered) = analyzeFrequency(audioBuffer, read)                        withContext(Dispatchers.Main) {                            detectedFrequencyTextView.text = "Detected Freq: %.2f Hz".format(detectedFreq)                            if (triggered) {                                // This is where you'd trigger your E72 notification                                appendLog("${detectedFreq.toInt()}Hz resonance detectedâ€”Zone Alpha scanned, scroll etched.")                                // Potentially play a sound, show a dialog, etc.                            }                        }                    } else if (read > 0) {                        Log.w("FogSonar", "Read less than FFT_SIZE samples: $read")                    }                }            }            Log.d("FogSonar", "Recording started.")        } else {            statusTextView.text = "Failed to initialize AudioRecord."            Log.e("FogSonar", "AudioRecord not initialized.")        }    }    private fun stopRecording() {        isRecording = false        audioJob?.cancel()        audioRecord?.apply {            stop()            release()        }        audioRecord = null        statusTextView.text = "Sonar stopped."        startStopButton.text = "Start Sonar"        detectedFrequencyTextView.text = "Detected Freq: -- Hz"        appendLog("Sonar stopped.")        Log.d("FogSonar", "Recording stopped.")    }    // --- Basic FFT Implementation (Conceptual for demonstration) ---    // This is a very simplified FFT and may not be as accurate as dedicated libraries.    // It's here to demonstrate the workflow.    private fun analyzeFrequency(audioBuffer: ShortArray, readSize: Int): Pair<Double, Boolean> {        if (readSize == 0 || readSize != FFT_SIZE) return Pair(0.0, false)        val real = DoubleArray(FFT_SIZE)        val imag = DoubleArray(FFT_SIZE)        // Apply a Hanning window and convert to Double        for (i in 0 until FFT_SIZE) {            val window = 0.5 * (1.0 - cos(2 * PI * i / (FFT_SIZE - 1)))            real[i] = audioBuffer[i] * window / Short.MAX_VALUE.toDouble()            imag[i] = 0.0 // Initialize imaginary part to zero        }        // Perform in-place FFT (simplified Cooley-Tukey algorithm structure)        fft(real, imag, false) // `false` for forward FFT        var maxMagnitude = 0.0        var maxIndex = 0        // Find the peak frequency in the positive spectrum        // We only care about the first half of the FFT result (up to N/2)        for (i in 0 until FFT_SIZE / 2) {            val magnitude = sqrt(real[i] * real[i] + imag[i] * imag[i])            if (magnitude > maxMagnitude) {                maxMagnitude = magnitude                maxIndex = i            }        }        val detectedFreq = maxIndex * (SAMPLE_RATE.toDouble() / FFT_SIZE)        // Check if detected frequency is close to any target frequency        var triggered = false        for (targetFreq in TARGET_FREQUENCIES) {            if (detectedFreq >= targetFreq - FREQUENCY_TOLERANCE &&                detectedFreq <= targetFreq + FREQUENCY_TOLERANCE) {                triggered = true                break            }        }        return Pair(detectedFreq, triggered)    }    // Simplified FFT algorithm (Cooley-Tukey, recursive form usually)    // This is a placeholder and should ideally be replaced by a library.    private fun fft(real: DoubleArray, imag: DoubleArray, inverse: Boolean) {        val n = real.size        if (n <= 1) return        val evenReal = DoubleArray(n / 2)        val evenImag = DoubleArray(n / 2)        val oddReal = DoubleArray(n / 2)        val oddImag = DoubleArray(n / 2)        for (k in 0 until n / 2) {            evenReal[k] = real[2 * k]            evenImag[k] = imag[2 * k]            oddReal[k] = real[2 * k + 1]            oddImag[k] = imag[2 * k + 1]        }        fft(evenReal, evenImag, inverse)        fft(oddReal, oddImag, inverse)        for (k in 0 until n / 2) {            val angle = 2 * PI * k / n * (if (inverse) -1 else 1)            val wkReal = cos(angle)            val wkImag = sin(angle)            val oddTermReal = oddReal[k] * wkReal - oddImag[k] * wkImag            val oddTermImag = oddReal[k] * wkImag + oddImag[k] * wkReal            real[k] = evenReal[k] + oddTermReal            imag[k] = evenImag[k] + oddTermImag            real[k + n / 2] = evenReal[k] - oddTermReal            imag[k + n / 2] = evenImag[k] - oddTermImag        }        if (inverse) {            for (k in 0 until n) {                real[k] /= n                imag[k] /= n            }        }    }    private fun appendLog(message: String) {        val timestamp = java.text.SimpleDateFormat("HH:mm:ss", java.util.Locale.getDefault()).format(java.util.Date())        val currentLog = logTextView.text.toString()        val newLog = "$timestamp - $message\n$currentLog"        // Keep log to a reasonable length        logTextView.text = newLog.take(2000)    }    override fun onDestroy() {        super.onDestroy()        stopRecording()        scope.cancel() // Cancel the coroutine scope when the activity is destroyed    }}